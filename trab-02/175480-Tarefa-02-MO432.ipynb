{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa-02. MO432.\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados\n",
    "\n",
    "Abaixo realizamos a leitura dos dados de entrada a partir do arquivo CSV, utilizando a API do \"pandas\". São removidas as colunas \"Next_Tmin\" e \"Date\", conforme solicitado no roteiro, além de todas as linhas que contenham valores faltantes (\"nan\").\n",
    "\n",
    "Em seguida, separamos os dados de entrada da regressão (\"X_data\") e os dados alvo (\"y_data\"), fazendo *centering* e *scaling* na entrada em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem os dados do arquivo CSV.\n",
    "df = read_csv(\"Bias_correction_ucl.csv\")\n",
    "# Elimina a coluna Next_Tmin.\n",
    "df = df.drop(columns=[\"Next_Tmin\"])\n",
    "# Elimina a coluna Date\n",
    "df = df.drop(columns=[\"Date\"])\n",
    "# Elimina todas as linhas que contenham NAN (valor faltante).\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "# Passando os dados para um dataset numpy\n",
    "y_data = df[\"Next_Tmax\"].to_numpy()\n",
    "X_data = df.drop(columns=\"Next_Tmax\").to_numpy()\n",
    "\n",
    "# Scaling dos dados em X.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, medida de erro e busca de hiperparâmetros.\n",
    "\n",
    "Usamos RMSE como medida de erro dos algoritmos de regressão, utilizando a repetição em 5-fold e buscando os hiperparâmetros utilizando o *random search* ou o *grid search* do pacote sklearn, a depender do exercício. Para comparar com os valores obtidos com o algoritmo padrão do sklearn, utilizamos o método *cross-validation*, que utiliza a validação cruzada sem desempenhar busca por qualquer parâmetro.\n",
    "\n",
    "### Regressão Linear\n",
    "\n",
    "Abaixo realizamos a regressão linear por método dos mínimos quadrados, que não aplica hiperparâmetros e é o método de regressão mais rápido deste roteiro. O erro RMSE médio das 5 repetições (folds) é de 1.4668565460537988°C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------LINEAR_REGRESSION---------------------\n",
      "\n",
      "RMSE para cada repetição: \n",
      " [1.49934913 1.47853876 1.45404056 1.4510827  1.45127158]\n",
      "\n",
      "\n",
      "RMSE médio:  1.4668565460537988\n"
     ]
    }
   ],
   "source": [
    "# ============LINEAR-REGRESSION=============================================\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LinearRegression()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\n---------------------LINEAR_REGRESSION---------------------\")\n",
    "\n",
    "print(\"\\nRMSE para cada repetição: \\n\", (-cv_results[\"test_MSE\"]) ** (1 / 2))\n",
    "\n",
    "print(\"\\n\\nRMSE médio: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão linear com regularização L2\n",
    "\n",
    "Realizamos a regressão linear com regularização por norma L2 (Ridge regression) utilizando a API de regressores do sklearn buscando o hiperparâmetro alpha de $10^{-3} \\text{ a } 10^3$, uniforme no expoente. O melhor RMSE obtido na média da validação cruzada é de 1.4668565552684352°C, para $\\alpha=0.001$, contra RMSE de 1.4668660324711131°C utilizando o alpha unitário default do sklearn. A diferença é pequena, mas o melhor resultado foi obtido com o menor valor de alpha possível, o que indica que este modelo não sofre de significativo overfitting, o que já se espera pelo fato de não utilizar funções não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------LINEAR_REGRESSION_L2-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Melhor error score: \n",
      " 1.4668565552684352\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Score RMSE default do sklearn: \n",
      " 1.4668660324711131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "# ============L2-RIDGE-REGRESSION===========================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "alpha = 10 ** np.linspace(-3, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'alpha': alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = Ridge()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------------LINEAR_REGRESSION_L2-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "# Deafult do sklearn. Coloquei uma lista de 10 parametros iguais so pra nao dar warning, performance nao eh critico aqui\n",
    "alpha = [1.0] * 10\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'alpha': alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = Ridge()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\nScore RMSE default do sklearn: \\n\", -cv_results.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão linear com regularização L1\n",
    "\n",
    "Realizamos a regressão linear com regularização por norma L1 (Lasso regression) utilizando a API de regressores do sklearn buscando o hiperparâmetro alpha de $10^{-3} \\text{ a } 10^3$, uniforme no expoente. O melhor RMSE obtido na média da validação cruzada é de 1.4668877424692912°C, para $\\alpha=0.001$, contra RMSE de 1.9815798242208555°C utilizando o alpha unitário default do sklearn. A diferença é de mais de 30%, e o melhor resultado foi obtido com o menor valor de alpha possível, o que indica que este modelo não sofre de significativo overfitting, o que já se espera pelo fato de não utilizar funções não lineares. Além disso, a diferença entre o modelo com melhor resultado (baixa regularização) contra o default (maior peso na regularização), indica que a norma L1 prejudica o aprendizado neste caso, provavelmente reduzindo drasticamente o peso sobre importantes dados de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------LINEAR_REGRESSION_L1-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 1.4668877424692912\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score RMSE default do sklearn: \n",
      " 1.9815798242208555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "# ============L1-LASSO-REGRESSION===========================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "alpha = 10 ** np.linspace(-3, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'alpha': alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = Lasso()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------------LINEAR_REGRESSION_L1-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "# Deafult do sklearn. Coloquei uma lista de 10 parametros iguais so pra nao dar warning, performance nao eh critico aqui\n",
    "alpha = [1.0] * 10\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'alpha': alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = Lasso()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\nScore RMSE default do sklearn: \\n\", -cv_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Linear\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVR com ativação linear retornou um RMSE de 1.4556835168247064°C, para $\\epsilon = 0.1$ e $c=5.46874897339475$, contra RMSE de 1.4713019150729336 utilizando os parâmetros default. Estes são valores mutio próximos aos obtidos pela regressão linear comum e descartam a utilização do SVR com ativação Linear para este tipo de problema, já que sua execução levou cerca de 2h, contra um resultado quase instantâneo da regressão linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 67.2min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 78.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVR-SVM-LINEAR----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=5.46874897339475, cache_size=7000, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='scale', kernel='linear', max_iter=-1, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 1.4556835168247064\n",
      "\n",
      "Score RMSE parâmetros default:  1.4713019150729336\n"
     ]
    }
   ],
   "source": [
    "# ============SVR-SVM-LINEAR================================================\n",
    "\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.linspace(-5, 15, 10)\n",
    "epsilon = np.array(random.choices([0.1, 0.3], k=10))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'epsilon': epsilon}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVR(max_iter=-1, cache_size=7000, kernel=\"linear\")\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVR-SVM-LINEAR----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVR(max_iter=-1, cache_size=7000, kernel=\"linear\")\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR com kernel RBF\n",
    "\n",
    "Este foi o regressor que obteve o melhor RMSE do roteiro, sendo de 0.9407269250783268°C para $c=5.46874897339475$, $\\epsilon = 0.1$ e $\\gamma = 0.08185402239753949$, contra RMSE de 1.193287479822758°C para os parâmetros default do sklearn. O tempo de treinamento para convergir é elevado, sendo que o processo de busca levou cerca de 2h, indicando que este método vale a pena se houver necessidade de um desempenho extremamente elevado e houver tempo disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVR-SVM-RBF----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=5.46874897339475, cache_size=7000, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma=0.08185402239753949, kernel='rbf', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9407269250783268\n",
      "\n",
      "Score RMSE parâmetros default:  1.193287479822758\n"
     ]
    }
   ],
   "source": [
    "# ============SVR-SVM-RBF================================================\n",
    "\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.linspace(-5, 15, 10)\n",
    "gamma = 2 ** np.linspace(-9, 3, 10)\n",
    "epsilon = np.array(random.choices([0.1, 0.3], k=10))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma, 'epsilon': epsilon}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVR(max_iter=-1, cache_size=7000, kernel=\"rbf\")\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVR-SVM-RBF----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVR(max_iter=-1, cache_size=7000, kernel=\"rbf\")\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Na célula abaixo, realizamos a regressão por meio do \"*K-nearest neighbors*\" regressor, que seleciona os \"k\" valores mais próximos do dado a ser amostrado dentre os dados passados para aprendizado e retorna uma média que pode ser ponderada em função da distância de cada um. Nota-se que o erro obtido pelo melhor parâmetro encontrado (k=192 vizinhos) é de 1.740118737742985°C, enquanto que o erro RMSE dos parâmetros default do sklearn foi de 1.2702952951681985°C. Isto provavelmente se deve ao fato que o melhor valor para \"k\" seria um número pequeno, mas como amostramos apenas 10 números aleatórios entre 1 e 1000 para \"k\", provavelmente não obtivemos um valor de vizinhos que superasse o default do método. Uma sugestão é fazer uma busca refinada entre k=5 (default) e k=192 (melhor do random search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------KNeighborsRegressor----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=192, p=2,\n",
      "                    weights='uniform')\n",
      "\n",
      "Melhor error score: \n",
      " 1.740118737742985\n",
      "\n",
      "Score RMSE parâmetros default:  1.2702952951681985\n"
     ]
    }
   ],
   "source": [
    "# ============KNeighborsRegressor===========================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_neighbors = np.linspace(1, 1000, 10).astype(\"int32\")\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_neighbors': n_neighbors}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsRegressor()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------KNeighborsRegressor----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsRegressor()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "Utilizando a MLP para regressão, fica clara a atuação do teorema da aproximação universal, que prevê que uma MLP com uma única camada oculta é capaz de aproximar qualquer função contínua se forem fornecidos suficientes neurônios para a camada oculta, bem como épocas ou iterações do treino. Isto se mostra no fato que o regressor encontrou que 20 (máximo de) neurônios oferecidos para a camada oculta durante o treinamento produzia a melhor RMSE, de 1.9043734674080024°C, enquanto que o default do sklearn produziu uma RMSE ainda melhor, de 1.2823751962533572°C, por utilizar 100 neurônios na camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------MLPRegressor-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=20, learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 1.873226195679314\n",
      "\n",
      "Score RMSE parâmetros default:  1.2823751962533572\n"
     ]
    }
   ],
   "source": [
    "# ============MLPRegressor==================================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "hidden_layer_sizes = np.array(range(5, 21, 3))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPRegressor()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------MLPRegressor-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPRegressor()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão\n",
    "\n",
    "Ao se utilizar uma única árvore de decisão com prunning variável (ccp_alpha é o hiperparâmetro sendo buscado), obtivemos 1.4868828491655717°C como RMSE do melhor ccp_alpha, sendo este de 0.007660778015155692. O resultado foi melhor do que o default do sklearn, que obteve RMSE de 1.5454842700795675°C com ccp_alpha de zero, ou seja, sem prunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------DecisionTreeRegressor------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " DecisionTreeRegressor(ccp_alpha=0.007660778015155692, criterion='mse',\n",
      "                      max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best')\n",
      "\n",
      "Melhor error score: \n",
      " 1.4874135358036715\n",
      "\n",
      "Score RMSE parâmetros default:  1.5454842700795675\n"
     ]
    }
   ],
   "source": [
    "# ============DecisionTreeRegressor=========================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "ccp_alpha = np.linspace(0, 0.04, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'ccp_alpha': ccp_alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeRegressor()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------DecisionTreeRegressor------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeRegressor()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Utilizando o método Random Forest, que une múltiplas árvores de regressão por meio do voto majoritário, obtivemos um ganho elevado no RMSE, sendo de 0.9447367529767478°C com 1000 estimadores e no máximo 5 features, contra 1.0239742637984799°C utilizando os parâmetros default do sklearn, sendo ambos consideravelmente melhores que os demais métodos. Esta busca por hiperparâmetros mostrou que aumentar o número de árvores foi algo bom, mas que aumentar a quantidade de features pode não ser uma boa opção quando se trabalha com múltiplas árvores (Random Forest).\n",
    "\n",
    "O único contra deste método em relação ao anterior é a perda da possível interpretabilidade do método, já que não é mais explicável o que está sendo feito quando se tem um número grande de árvores atuano em conjunto, como é o caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------RandomForestRegressor------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features=5, max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9447367529767478\n",
      "\n",
      "Score RMSE parâmetros default:  1.0239742637984799\n"
     ]
    }
   ],
   "source": [
    "# ============RandomForestRegressor=========================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = [5, 10, 22]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'max_features': max_features}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestRegressor()\n",
    "cv_results = \\\n",
    "    GridSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                 param_grid=parametros,\n",
    "                 verbose=1,\n",
    "                 n_jobs=1,\n",
    "                 scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------RandomForestRegressor------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestRegressor()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM\n",
    "\n",
    "Por último, trbalhamos com o GBM (Gradient Boosting Regressor), que adiciona modelos treinados diferentemente enfileirando a saída de alguns como entrada do seguinte, de forma que os sistemas sendo adicionados possam treinar sobre as regiões onde os modelos anteriores mais erraram.\n",
    "\n",
    "O erro RMSE obtido com os melhores parâmetos encontrados foi de 1.0735283782351117°C, sendo os parâmetros de: n_estimators = 96, learning_rate = 0.3 e max_depth = 3. Pode-se concluir que mais estimadores tornam o modelo melhor, o learning rate de 0.3 simplesmente era pequeno o suficiente para a atividade e uma profundidade maior na árvore também ajuda a classficação.O RMSE obtido com o default foi de 1.2233210699332346°C.\n",
    "\n",
    "O RMSE deste método se aproximou do Random Forest e do SVR-RBF, que foram os melhores do estudo, indicando que se não for preciso um RMSE extremamente baixo, o tempo de treinamento deste modelo pode compensar, já que os métodos supracitados foram ordens de grandeza mais lentos que este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------GradientBoostingRegressor------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.3, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=96,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 1.0734665509968857\n",
      "\n",
      "Score RMSE parâmetros default:  1.2233210699332346\n"
     ]
    }
   ],
   "source": [
    "# ============GradientBoostingRegressor=====================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = np.linspace(5, 100, 10).astype(\"int32\")\n",
    "learning_rate = [0.01, 0.3]\n",
    "max_depth = [2, 3]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingRegressor()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------GradientBoostingRegressor------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", -cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingRegressor()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"MSE\": make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                            \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False)})\n",
    "\n",
    "print(\"\\nScore RMSE parâmetros default: \", ((-cv_results[\"test_MSE\"]) ** (1 / 2)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown PC at the end of training\n",
    "import os\n",
    "import time\n",
    "\n",
    "time.sleep(10 * 60)\n",
    "os.system(\"shutdown 0\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
