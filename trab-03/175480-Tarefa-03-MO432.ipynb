{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa-03. MO432.\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pandas import read_csv, get_dummies\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados\n",
    "\n",
    "Abaixo realizamos a leitura dos dados de entrada a partir do arquivo CSV, utilizando a API do \"pandas\". São removidas as colunas \"Next_Tmin\" e \"Date\", conforme solicitado no roteiro, além de todas as linhas que contenham valores faltantes (\"nan\").\n",
    "\n",
    "Em seguida, separamos os dados de entrada da regressão (\"X_data\") e os dados alvo (\"y_data\"), fazendo *centering* e *scaling* na entrada em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem os dados do arquivo CSV.\n",
    "df = read_csv(\"dados3.csv\")\n",
    "# # Elimina a coluna Next_Tmin.\n",
    "# df = df.drop(columns=[\"Next_Tmin\"])\n",
    "# # Elimina a coluna Date\n",
    "# df = df.drop(columns=[\"Date\"])\n",
    "# Elimina todas as linhas que contenham NAN (valor faltante).\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "get_dummies(df).to_csv(\"dados3-dummies.csv\")\n",
    "\n",
    "# OneHot encoding para converter vriaveis ctegoricas em dummy variables.\n",
    "df = get_dummies(df)\n",
    "\n",
    "# Passando os dados para um dataset numpy\n",
    "y_data = df[\"V15\"].to_numpy()\n",
    "X_data = df.drop(columns=\"V15\").to_numpy()\n",
    "\n",
    "# Scaling dos dados em X.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, medida de erro e busca de hiperparâmetros.\n",
    "\n",
    "Usamos AUC como medida de score dos algoritmos de regressão, utilizando a repetição em 5-fold e buscando os hiperparâmetros utilizando o *random search* ou o *grid search* do pacote sklearn, a depender do exercício. Para comparar com os valores obtidos com o algoritmo padrão do sklearn, utilizamos o método *cross-validation*, que utiliza a validação cruzada sem desempenhar busca por qualquer parâmetro.\n",
    "\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "Abaixo realizamos a regressão logística sem regulariazção, que não aplica hiperparâmetros e é o método de regressão mais rápido deste roteiro. O AUC médio das 5 repetições (folds) é de 0.9197457062275621."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9197457062275621\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression(penalty=\"none\", solver=\"lbfgs\")\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística com regularização L2\n",
    "\n",
    "Realizamos a regressão logística com regularização por norma L2 utilizando a API de classificadores do sklearn buscando o hiperparâmetro C de $10^{-3} \\text{ a } 10^3$, uniforme no expoente. O melhor AUC obtido na média da validação cruzada é de 0.9407038551439606, para $C=0.026020058428635535$, contra AUC de 0.9283532479273265 utilizando o C unitário default do sklearn. A diferença é pequena, mas o melhor resultado foi obtido com um pequeno valor de C possível na distribuição gerada, o que indica que este modelo não sofre de significativo overfitting, o que já se espera pelo fato de não utilizar funções não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression-L2----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " LogisticRegression(C=0.026020058428635535, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9407038551439606\n",
      "\n",
      "Score AUC parâmetros default:  0.9283532479273265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression-L2========================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 10 ** np.random.uniform(-3, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression-L2----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "Abaixo realizamos a classificação com Linear Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.9318615506427577."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------LDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9318615506427577\n"
     ]
    }
   ],
   "source": [
    "# ============LDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------LDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LinearDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA\n",
    "\n",
    "Abaixo realizamos a classificação com Quadratic Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.8205157842023286."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------QDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8205157842023286\n"
     ]
    }
   ],
   "source": [
    "# ============QDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------QDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = QuadraticDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação linear retornou um AUC de 0.92809192351247, para $C = 31.925195621733018$, contra AUC de 0.9207682232859031 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com ativação Linear para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-LINEAR----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=31.925195621733018, cache_size=7000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.92809192351247\n",
      "\n",
      "Score AUC parâmetros default:  0.9207682232859031\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-LINEAR================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-LINEAR----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC RBF\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação RBF (Radial basis function) retornou um AUC de 0.9336317703698913, para $C = 0.16414560961711494$, contra AUC de 0.9342224478698687 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com RBF para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão.\n",
    "\n",
    "Este resultado também demonstra que o default do sklearn é bem ajustado o suficiente, já que produziu resultado semelhante ao da busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-RBF----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=0.16414560961711494, cache_size=7000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.00699943241971803,\n",
      "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9336317703698913\n",
      "\n",
      "Score AUC parâmetros default:  0.9342224478698687\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-RBF===================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "gamma = 2 ** np.random.uniform(-9, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-RBF----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Abaixo utilizamos o método Naives Bayes com GaussianNB, que computa as ocorrências de cada combinação para estimar a probabiidade e a condicional de cada evento, além de fazer a predição com base no teorema de Bayes. O AUC obtido foi de 0.8632802184759667, um dos piores do roteiro, provavelmente pela pequena quantidade de dados do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------GaussianNB-Naive-Bayes----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8632802184759667\n"
     ]
    }
   ],
   "source": [
    "# ============GaussianNB-Naive-Bayes========================================\n",
    "\n",
    "print(\"\\n----------------GaussianNB-Naive-Bayes----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GaussianNB()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Na célula abaixo, realizamos a classificação por meio do \"*K-nearest neighbors*\" classificador, que seleciona os \"k\" valores mais próximos do dado a ser amostrado dentre os dados passados para aprendizado e retorna uma classe que pode ser ponderada em seus votos em função da distância de cada um. Nota-se que o AUC obtido pelo melhor parâmetro encontrado (k=187 vizinhos) é de 0.9273362726256549, enquanto que o AUC dos parâmetros default do sklearn foi de 0.8759436830922536. É um dos melhores métodos até agora, mas não superou a regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------KNeighborsClassifier----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=187, p=2,\n",
      "                     weights='uniform')\n",
      "\n",
      "Melhor error score: \n",
      " 0.9273362726256549\n",
      "\n",
      "Score AUC parâmetros default:  0.8759436830922536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# ============KNeighborsRegressor===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_neighbors = np.random.uniform(0, 150, 10).astype(\"int32\") * 2 + 1\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_neighbors': n_neighbors}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------KNeighborsClassifier----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------MLPClassifier-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=17, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9273499770680775\n",
      "\n",
      "Score AUC parâmetros default:  0.9142395181818566\n"
     ]
    }
   ],
   "source": [
    "# ============MLPClassifier=================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "hidden_layer_sizes = np.array(range(5, 21, 3))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------MLPClassifier-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter ccp_alpha for estimator DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best'). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 503, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/home/patrickctrf/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 224, in set_params\n    (key, self))\nValueError: Invalid parameter ccp_alpha for estimator DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best'). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8e325b6d8df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Realizamos a busca atraves do treinamento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcv_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--------------DecisionTreeClassifier------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter ccp_alpha for estimator DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best'). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# ============DecisionTreeClassifier=========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "ccp_alpha = np.random.uniform(0, 0.04, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'ccp_alpha': ccp_alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------DecisionTreeClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============RandomForestClassifier========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = [5, 8, 10]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'max_features': max_features}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    GridSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                 param_grid=parametros,\n",
    "                 verbose=1,\n",
    "                 refit=\"AUC\",\n",
    "                 n_jobs=1,\n",
    "                 scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------RandomForestClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============GradientBoostingClassifier====================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = np.random.uniform(5, 100, 10).astype(\"int32\")\n",
    "learning_rate = [0.01, 0.3]\n",
    "max_depth = [2, 3]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------GradientBoostingClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
