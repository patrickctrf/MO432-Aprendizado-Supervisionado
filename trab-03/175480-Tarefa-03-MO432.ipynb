{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa-03. MO432.\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pandas import read_csv, get_dummies\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados\n",
    "\n",
    "Abaixo realizamos a leitura dos dados de entrada a partir do arquivo CSV, utilizando a API do \"pandas\". São removidas as colunas \"Next_Tmin\" e \"Date\", conforme solicitado no roteiro, além de todas as linhas que contenham valores faltantes (\"nan\").\n",
    "\n",
    "Em seguida, separamos os dados de entrada da regressão (\"X_data\") e os dados alvo (\"y_data\"), fazendo *centering* e *scaling* na entrada em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem os dados do arquivo CSV.\n",
    "df = read_csv(\"dados3.csv\")\n",
    "# # Elimina a coluna Next_Tmin.\n",
    "# df = df.drop(columns=[\"Next_Tmin\"])\n",
    "# # Elimina a coluna Date\n",
    "# df = df.drop(columns=[\"Date\"])\n",
    "# Elimina todas as linhas que contenham NAN (valor faltante).\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "get_dummies(df).to_csv(\"dados3-dummies.csv\")\n",
    "\n",
    "# OneHot encoding para converter vriaveis ctegoricas em dummy variables.\n",
    "df = get_dummies(df)\n",
    "\n",
    "# Passando os dados para um dataset numpy\n",
    "y_data = df[\"V15\"].to_numpy()\n",
    "X_data = df.drop(columns=\"V15\").to_numpy()\n",
    "\n",
    "# Scaling dos dados em X.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, medida de erro e busca de hiperparâmetros.\n",
    "\n",
    "Usamos AUC como medida de score dos algoritmos de regressão, utilizando a repetição em 5-fold e buscando os hiperparâmetros utilizando o *random search* ou o *grid search* do pacote sklearn, a depender do exercício. Para comparar com os valores obtidos com o algoritmo padrão do sklearn, utilizamos o método *cross-validation*, que utiliza a validação cruzada sem desempenhar busca por qualquer parâmetro.\n",
    "\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "Abaixo realizamos a regressão logística sem regulariazção, que não aplica hiperparâmetros e é o método de regressão mais rápido deste roteiro. O AUC médio das 5 repetições (folds) é de 0.9197457062275621."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9197457062275621\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression(penalty=\"none\", solver=\"lbfgs\")\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística com regularização L2\n",
    "\n",
    "Realizamos a regressão logística com regularização por norma L2 utilizando a API de classificadores do sklearn buscando o hiperparâmetro C de $10^{-3} \\text{ a } 10^3$, uniforme no expoente. O melhor AUC obtido na média da validação cruzada é de 0.9407038551439606, para $C=0.026020058428635535$, contra AUC de 0.9283532479273265 utilizando o C unitário default do sklearn. A diferença é pequena, mas o melhor resultado foi obtido com um pequeno valor de C possível na distribuição gerada, o que indica que este modelo não sofre de significativo overfitting, o que já se espera pelo fato de não utilizar funções não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression-L2----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " LogisticRegression(C=0.026020058428635535, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9407038551439606\n",
      "\n",
      "Score AUC parâmetros default:  0.9283532479273265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression-L2========================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 10 ** np.random.uniform(-3, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression-L2----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "Abaixo realizamos a classificação com Linear Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.9318615506427577."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------LDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9318615506427577\n"
     ]
    }
   ],
   "source": [
    "# ============LDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------LDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LinearDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA\n",
    "\n",
    "Abaixo realizamos a classificação com Quadratic Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.8205157842023286."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------QDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8205157842023286\n"
     ]
    }
   ],
   "source": [
    "# ============QDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------QDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = QuadraticDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação linear retornou um AUC de 0.92809192351247, para $C = 31.925195621733018$, contra AUC de 0.9207682232859031 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com ativação Linear para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-LINEAR----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=31.925195621733018, cache_size=7000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.92809192351247\n",
      "\n",
      "Score AUC parâmetros default:  0.9207682232859031\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-LINEAR================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-LINEAR----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC RBF\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação RBF (Radial basis function) retornou um AUC de 0.9336317703698913, para $C = 0.16414560961711494$, contra AUC de 0.9342224478698687 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com RBF para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão.\n",
    "\n",
    "Este resultado também demonstra que o default do sklearn é bem ajustado o suficiente, já que produziu resultado semelhante ao da busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-RBF----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=0.16414560961711494, cache_size=7000, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.00699943241971803,\n",
      "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9336317703698913\n",
      "\n",
      "Score AUC parâmetros default:  0.9342224478698687\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-RBF===================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "gamma = 2 ** np.random.uniform(-9, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-RBF----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Abaixo utilizamos o método Naives Bayes com GaussianNB, que computa as ocorrências de cada combinação para estimar a probabiidade e a condicional de cada evento, além de fazer a predição com base no teorema de Bayes. O AUC obtido foi de 0.8632802184759667, um dos piores do roteiro, provavelmente pela pequena quantidade de dados do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------GaussianNB-Naive-Bayes----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8632802184759667\n"
     ]
    }
   ],
   "source": [
    "# ============GaussianNB-Naive-Bayes========================================\n",
    "\n",
    "print(\"\\n----------------GaussianNB-Naive-Bayes----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GaussianNB()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Na célula abaixo, realizamos a classificação por meio do \"*K-nearest neighbors*\" classificador, que seleciona os \"k\" valores mais próximos do dado a ser amostrado dentre os dados passados para aprendizado e retorna uma classe que pode ser ponderada em seus votos em função da distância de cada um. Nota-se que o AUC obtido pelo melhor parâmetro encontrado (k=187 vizinhos) é de 0.9273362726256549, enquanto que o AUC dos parâmetros default do sklearn foi de 0.8759436830922536. É um dos melhores métodos até agora, mas não superou a regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------KNeighborsClassifier----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=187, p=2,\n",
      "                     weights='uniform')\n",
      "\n",
      "Melhor error score: \n",
      " 0.9273362726256549\n",
      "\n",
      "Score AUC parâmetros default:  0.8759436830922536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# ============KNeighborsRegressor===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_neighbors = np.random.uniform(0, 150, 10).astype(\"int32\") * 2 + 1\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_neighbors': n_neighbors}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------KNeighborsClassifier----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------MLPClassifier-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=17, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9273499770680775\n",
      "\n",
      "Score AUC parâmetros default:  0.9142395181818566\n"
     ]
    }
   ],
   "source": [
    "# ============MLPClassifier=================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "hidden_layer_sizes = np.array(range(5, 21, 3))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------MLPClassifier-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------DecisionTreeClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " DecisionTreeClassifier(ccp_alpha=0.01750910956028458)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9091774473094114\n",
      "\n",
      "Score AUC parâmetros default:  0.8272019408426212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "# ============DecisionTreeClassifier=========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "ccp_alpha = np.random.uniform(0, 0.04, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'ccp_alpha': ccp_alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------DecisionTreeClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------RandomForestClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " RandomForestClassifier(max_features=10, n_estimators=1000)\n",
      "\n",
      "Melhor error score: \n",
      " 0.943294639551229\n",
      "\n",
      "Score AUC parâmetros default:  0.9395490611060222\n"
     ]
    }
   ],
   "source": [
    "# ============RandomForestClassifier========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = [5, 8, 10]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'max_features': max_features}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    GridSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                 param_grid=parametros,\n",
    "                 verbose=1,\n",
    "                 refit=\"AUC\",\n",
    "                 n_jobs=1,\n",
    "                 scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------RandomForestClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------GradientBoostingClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " GradientBoostingClassifier(learning_rate=0.01, max_depth=2, n_estimators=96)\n",
      "\n",
      "Melhor error score: \n",
      " 0.9412940669742994\n",
      "\n",
      "Score AUC parâmetros default:  0.9379176895304149\n"
     ]
    }
   ],
   "source": [
    "# ============GradientBoostingClassifier====================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = np.random.uniform(5, 100, 10).astype(\"int32\")\n",
    "learning_rate = [0.01, 0.3]\n",
    "max_depth = [2, 3]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------GradientBoostingClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor error score: \\n\", cv_results.best_score_)\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
