{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa-03. MO432.\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pandas import read_csv, get_dummies\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados\n",
    "\n",
    "Abaixo realizamos a leitura dos dados de entrada a partir do arquivo CSV, utilizando a API do \"pandas\". São removidas as colunas \"Next_Tmin\" e \"Date\", conforme solicitado no roteiro, além de todas as linhas que contenham valores faltantes (\"nan\").\n",
    "\n",
    "Em seguida, separamos os dados de entrada da regressão (\"X_data\") e os dados alvo (\"y_data\"), fazendo *centering* e *scaling* na entrada em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem os dados do arquivo CSV.\n",
    "df = read_csv(\"dados3.csv\")\n",
    "# # Elimina a coluna Next_Tmin.\n",
    "# df = df.drop(columns=[\"Next_Tmin\"])\n",
    "# # Elimina a coluna Date\n",
    "# df = df.drop(columns=[\"Date\"])\n",
    "# Elimina todas as linhas que contenham NAN (valor faltante).\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "get_dummies(df).to_csv(\"dados3-dummies.csv\")\n",
    "\n",
    "# OneHot encoding para converter vriaveis ctegoricas em dummy variables.\n",
    "df = get_dummies(df)\n",
    "\n",
    "# Passando os dados para um dataset numpy\n",
    "y_data = df[\"V15\"].to_numpy()\n",
    "X_data = df.drop(columns=\"V15\").to_numpy()\n",
    "\n",
    "# Scaling dos dados em X.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, medida de erro e busca de hiperparâmetros.\n",
    "\n",
    "Usamos AUC como medida de score dos algoritmos de regressão, utilizando a repetição em 5-fold e buscando os hiperparâmetros utilizando o *random search* ou o *grid search* do pacote sklearn, a depender do exercício. Para comparar com os valores obtidos com o algoritmo padrão do sklearn, utilizamos o método *cross-validation*, que utiliza a validação cruzada sem desempenhar busca por qualquer parâmetro.\n",
    "\n",
    "### AUC da curva ROC\n",
    "A curva ROC nos dá a relação entre a quantidade de Verdadeiros Positivos e Falsos positivos em função do limiar de decisão esccolhido. A AUC é a área debaixo desta curve e, logicamente, quanto maior, melhor será a distinção que o modelo proporciona na hora de classificar os dados em diferentes conjuntos.\n",
    "\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "Abaixo realizamos a regressão logística sem regulariazção, que não aplica hiperparâmetros e é o método de regressão mais rápido deste roteiro. O AUC médio das 5 repetições (folds) é de 0.9197457062275621."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9197457062275621\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression(penalty=\"none\", solver=\"lbfgs\")\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística com regularização L2\n",
    "\n",
    "Realizamos a regressão logística com regularização por norma L2 utilizando a API de classificadores do sklearn buscando o hiperparâmetro C de $10^{-3} \\text{ a } 10^3$, uniforme no expoente. O melhor AUC obtido na média da validação cruzada é de 0.9407038551439606, para $C=0.026020058428635535$, contra AUC de 0.9283532479273265 utilizando o C unitário default do sklearn. A diferença é pequena, mas o melhor resultado foi obtido com um pequeno valor de C possível na distribuição gerada, o que indica que este modelo não sofre de significativo overfitting, o que já se espera pelo fato de não utilizar funções não lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------Logistic-Regression-L2----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " LogisticRegression(C=0.026020058428635535)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9405899735641581 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9282021419350347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "# ============Logistic-Regression-L2========================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 10 ** np.random.uniform(-3, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------Logistic-Regression-L2----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LogisticRegression()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "Abaixo realizamos a classificação com Linear Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.9318615506427577. Como ele possui menos parâmetros a se ajustar que o QDA, seu resultado fica dentre os melhores do roteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------LDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.9318615506427577\n"
     ]
    }
   ],
   "source": [
    "# ============LDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------LDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = LinearDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA\n",
    "\n",
    "Abaixo realizamos a classificação com Quadratic Discriminant Analysis, que não aplica hiperparâmetros. O AUC médio das 5 repetições (folds) é de 0.8205157842023286. Mesmo sendo um método ainda mais flexível que o LDA, seus resultados são piores, e isto se deve ao fato que este modelo quadrático requer mais parâmetros a se ajustar. Em um dataset com menos de 1000 observações como este, o modelo fica subtreinado, obtendo um resultado de validação ruim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------QDA----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8205157842023286\n"
     ]
    }
   ],
   "source": [
    "# ============QDA===========================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "print(\"\\n----------------QDA----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = QuadraticDiscriminantAnalysis()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação linear retornou um AUC de 0.92809192351247, para $C = 31.925195621733018$, contra AUC de 0.9207682232859031 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com ativação Linear para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-LINEAR----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=31.925195621733018, cache_size=7000, kernel='linear', probability=True)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9280919235124699 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9207496953677872\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-LINEAR================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-LINEAR----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"linear\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC RBF\n",
    "\n",
    "A busca por hiperparâmetros utilizando SVC com ativação RBF (Radial basis function) retornou um AUC de 0.9336317703698913, para $C = 0.16414560961711494$ e  $Gamma = 0.00699943241971803$, contra AUC de 0.9342224478698687 utilizando os parâmetros default. Estes são valores inferiores aos da regressão logística com L2 e descartam a utilização do SVR com RBF para este tipo de problema, já que sua execução levou cerca de 10min, contra um resultado quase instantâneo da regressão.\n",
    "\n",
    "Este resultado também demonstra que o default do sklearn é bem ajustado o suficiente, já que produziu resultado semelhante ao da busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------SVC-SVM-RBF----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVC(C=0.16414560961711494, cache_size=7000, gamma=0.00699943241971803,\n",
      "    probability=True)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9336222210956361 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9341840620406815\n"
     ]
    }
   ],
   "source": [
    "# ============SVC-SVM-RBF===================================================\n",
    "np.random.seed(3333)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 10)\n",
    "gamma = 2 ** np.random.uniform(-9, 3, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=3333)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------SVC-SVM-RBF----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = SVC(max_iter=-1, cache_size=7000, kernel=\"rbf\", probability=True)\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Abaixo utilizamos o método Naives Bayes com GaussianNB, que computa as ocorrências de cada combinação para estimar a probabiidade e a condicional de cada evento, além de fazer a predição com base no teorema de Bayes. O AUC obtido foi de 0.8632802184759667, um dos piores do roteiro, provavelmente pela pequena quantidade de dados do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------GaussianNB-Naive-Bayes----------------\n",
      "\n",
      "Score AUC parâmetros default:  0.8632802184759667\n"
     ]
    }
   ],
   "source": [
    "# ============GaussianNB-Naive-Bayes========================================\n",
    "\n",
    "print(\"\\n----------------GaussianNB-Naive-Bayes----------------\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GaussianNB()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Na célula abaixo, realizamos a classificação por meio do \"*K-nearest neighbors*\" classificador, que seleciona os \"k\" valores mais próximos do dado a ser amostrado dentre os dados passados para aprendizado e retorna uma classe que pode ser ponderada em seus votos em função da distância de cada um. Nota-se que o AUC obtido pelo melhor parâmetro encontrado (k=187 vizinhos) é de 0.9273362726256549, enquanto que o AUC dos parâmetros default do sklearn foi de 0.8759436830922536. É um dos melhores métodos até agora, mas não superou a regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------KNeighborsClassifier----------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " KNeighborsClassifier(n_neighbors=187)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9273362726256549 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.8759436830922536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# ============KNeighborsRegressor===========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_neighbors = np.random.uniform(0, 150, 10).astype(\"int32\") * 2 + 1\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_neighbors': n_neighbors}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n----------------KNeighborsClassifier----------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = KNeighborsClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "Utilizando a MLP para classificação, fica clara a atuação do teorema da aproximação universal, que prevê que uma MLP com uma única camada oculta é capaz de aproximar qualquer função contínua se forem fornecidos suficientes neurônios para a camada oculta, bem como épocas ou iterações do treino. Isto se mostra no fato que o classificador encontrou que 17 neurônios oferecidos para a camada oculta durante o treinamento produzia a melhor AUC, de 0.9273499770680775, enquanto que o default do sklearn produziu um AUC inferior, de 0.9142395181818566, por utilizar 100 neurônios na camada oculta. Lembrando que adicionar neurônios demais para poucos dados implica em ter parâmetros subajustados, o que explica os resultaos inferiores no default com mais neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------MLPClassifier-------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " MLPClassifier(hidden_layer_sizes=17)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9289030823173332 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9142395181818566\n"
     ]
    }
   ],
   "source": [
    "# ============MLPClassifier=================================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "hidden_layer_sizes = np.array(range(5, 21, 3))\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n---------------MLPClassifier-------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = MLPClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão\n",
    "\n",
    "Ao se utilizar uma única árvore de decisão com prunning variável (ccp_alpha é o hiperparâmetro sendo buscado), obtivemos 0.9091774473094114 como AUC do melhor ccp_alpha, sendo este de 0.01750910956028458. O resultado foi melhor do que o default do sklearn, que obteve AUC de 0.8272019408426212 com ccp_alpha de zero, ou seja, sem prunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "--------------DecisionTreeClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " DecisionTreeClassifier(ccp_alpha=0.01750910956028458)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9091774473094114 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.8272019408426212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# ============DecisionTreeClassifier=========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "ccp_alpha = np.random.uniform(0, 0.04, 10)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'ccp_alpha': ccp_alpha}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------DecisionTreeClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = DecisionTreeClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Utilizando o método Random Forest, que une múltiplas árvores de decisão por meio do voto majoritário, obtivemos um ganho elevado no AUC, sendo de 0.943294639551229 com 1000 estimadores e no máximo 10 features, contra 0.9395490611060222 utilizando os parâmetros default do sklearn, sendo ambos consideravelmente melhores que os demais métodos. Esta busca por hiperparâmetros mostrou que aumentar o número de árvores foi algo bom, assim como aumentar a quantidade de features.\n",
    "\n",
    "O único contra deste método em relação ao anterior é a perda da possível interpretabilidade do método, já que não é mais explicável o que está sendo feito quando se tem um número grande de árvores atuando em conjunto, como é o caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------RandomForestClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " RandomForestClassifier(max_features=10, n_estimators=1000)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.943294639551229 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9395490611060222\n"
     ]
    }
   ],
   "source": [
    "# ============RandomForestClassifier========================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = [5, 8, 10]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'max_features': max_features}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    GridSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                 param_grid=parametros,\n",
    "                 verbose=1,\n",
    "                 refit=\"AUC\",\n",
    "                 n_jobs=1,\n",
    "                 scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------RandomForestClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = RandomForestClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM\n",
    "\n",
    "Por último, trabalhamos com o GBM (Gradient Boosting Classifier), que adiciona modelos treinados com diferentes pesos nas regiões de maior erro do anterior, de forma que os sistemas sendo adicionados possam treinar sobre as regiões onde os modelos anteriores mais erraram.\n",
    "\n",
    "O AUC obtido com os melhores parâmetos encontrados foi de 0.9412940669742994, sendo os parâmetros de: n_estimators = 96, learning_rate = 0.01 e max_depth = 2. Pode-se concluir que mais estimadores tornam o modelo melhor, o learning rate de 0.01 demonstrou uma precisão melhor no ajuste do modelo e uma profundidade menor na árvore foi suficiente a classficação.O AUC obtido com o default foi de 0.9379176895304149."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------GradientBoostingClassifier------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " GradientBoostingClassifier(learning_rate=0.01, max_depth=2, n_estimators=96)\n",
      "\n",
      "Melhor AUC score: \n",
      " 0.9412940669742994 \n",
      "\n",
      "\n",
      "Score AUC parâmetros default:  0.9379176895304149\n"
     ]
    }
   ],
   "source": [
    "# ============GradientBoostingClassifier====================================\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente.\n",
    "n_estimators = np.random.uniform(5, 100, 10).astype(\"int32\")\n",
    "learning_rate = [0.01, 0.3]\n",
    "max_depth = [2, 3]\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    RandomizedSearchCV(estimator=regressor, cv=shuffle_splitter,\n",
    "                       param_distributions=parametros,\n",
    "                       refit=\"AUC\",\n",
    "                       verbose=1,\n",
    "                       n_jobs=4,\n",
    "                       scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "cv_results.fit(X_data_scaled, y_data)\n",
    "\n",
    "print(\"\\n--------------GradientBoostingClassifier------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", cv_results.best_estimator_)\n",
    "\n",
    "print(\"\\nMelhor AUC score: \\n\", cv_results.best_score_, \"\\n\")\n",
    "\n",
    "shuffle_splitter = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1234)\n",
    "regressor = GradientBoostingClassifier()\n",
    "cv_results = \\\n",
    "    cross_validate(estimator=regressor, X=X_data_scaled, y=y_data,\n",
    "                   cv=shuffle_splitter,\n",
    "                   scoring={\"AUC\": make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)})\n",
    "\n",
    "print(\"\\nScore AUC parâmetros default: \", (cv_results[\"test_AUC\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Random Forest, GBM e Logistic Regression com regularização L2 foram os métodos com melhores resultados deste roteiro, respectivamente. O AUC obtido por cada um deles foi praticamente o mesmo, diferindo por milésimos.\n",
    "\n",
    "Entretanto, a regressão logística foi consideravelmente mais rápida, podendo ser um método preferível na maioria dos casos.\n",
    "\n",
    "Também ficou evidente o fato que não é conveniente o modelo ter mais flexibilidade se o tamanho do dataset para treiná-lo não é grande o suficiente, pois produz parâmetros subajustados que desempenham mal as tarefas de validação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
